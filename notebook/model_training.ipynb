{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1a2df9",
   "metadata": {},
   "source": [
    "#### General Steps to Follow\n",
    "\n",
    "1. Importing Packages\n",
    "2. Defining x_train, x_test, y_train, y_test\n",
    "3. Building the Neural Network\n",
    "4. Training the Neural Network\n",
    "5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144b3263",
   "metadata": {},
   "source": [
    "## 1) Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ad34cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669c6cb",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ce88d",
   "metadata": {},
   "source": [
    "## 2) Defining x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5b5fe",
   "metadata": {},
   "source": [
    "#### Loading the training and test data from \"my data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33675ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(\"../my data/train_data.npy\", allow_pickle = True)\n",
    "test_data = np.load(\"../my data/test_data.npy\"  , allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d125c3",
   "metadata": {},
   "source": [
    "* x_train and x_test will contain the images.\n",
    "* y_train and y_test will contain the label of each image:\n",
    "  - 1 if it is a happy image.\n",
    "  - 0 if it is a sad image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa1c06ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data[:,0]\n",
    "y_train = train_data[:,1]\n",
    "x_test = test_data[:,0]\n",
    "y_test = test_data[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f09958",
   "metadata": {},
   "source": [
    "#### Reshaping the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aa0657",
   "metadata": {},
   "source": [
    "* I created temp varaibles and deleted them to save memory because the data size is large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3a09dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = x_train.tolist()\n",
    "del x_train\n",
    "x_train = np.array(temp)\n",
    "del temp\n",
    "\n",
    "temp = x_test.tolist()\n",
    "del x_test\n",
    "x_test = np.array(temp)\n",
    "del temp\n",
    "\n",
    "temp = y_train.tolist()\n",
    "del y_train\n",
    "y_train = tf.convert_to_tensor(temp)\n",
    "del temp\n",
    "\n",
    "temp = y_test.tolist()\n",
    "del y_test\n",
    "y_test = tf.convert_to_tensor(temp)\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca17c4",
   "metadata": {},
   "source": [
    "#### Checking the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df046382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train    :  (6897, 100, 100, 3)\n",
      "Shape of y_train    :  (6897,)\n",
      "--------------------------------------------------\n",
      "Shape of x_test    :  (1702, 100, 100, 3)\n",
      "Shape of y_test    :  (1702,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of x_train    : \", x_train.shape)\n",
    "print(\"Shape of y_train    : \", y_train.shape)\n",
    "\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "print(\"Shape of x_test    : \", x_test.shape)\n",
    "print(\"Shape of y_test    : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17aa7c",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceba069",
   "metadata": {},
   "source": [
    "## 3) Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "421643e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "model = Sequential(\n",
    "    [\n",
    "        Conv2D(32, (3,3), activation = 'relu', input_shape = (100,100,3)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "\n",
    "        Conv2D(64, (3,3), activation = 'relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "\n",
    "        Conv2D(32, (3,3), activation = 'relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation = 'relu'),\n",
    "        Dense(1, activation = 'linear')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7a5b9c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 98, 98, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 49, 49, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 47, 47, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPooli  (None, 23, 23, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 21, 21, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 21, 21, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 10, 10, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               819456    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 858081 (3.27 MB)\n",
      "Trainable params: 857825 (3.27 MB)\n",
      "Non-trainable params: 256 (1.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18adae",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b7a30",
   "metadata": {},
   "source": [
    "## 4) Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d09161f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.01),\n",
    "    loss = BinaryCrossentropy(from_logits = True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1272e782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "216/216 [==============================] - 39s 174ms/step - loss: 0.4084\n",
      "Epoch 2/5\n",
      "216/216 [==============================] - 37s 172ms/step - loss: 0.0818\n",
      "Epoch 3/5\n",
      "216/216 [==============================] - 37s 172ms/step - loss: 0.0638\n",
      "Epoch 4/5\n",
      "216/216 [==============================] - 39s 179ms/step - loss: 0.0550\n",
      "Epoch 5/5\n",
      "216/216 [==============================] - 38s 175ms/step - loss: 0.0639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25eb87595d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77a1ad",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57585ed1",
   "metadata": {},
   "source": [
    "## 5) Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af298fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(y, y_hat):\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    y_hat = y_hat.numpy()\n",
    "    y = y.numpy()\n",
    "    y_temp = np.zeros(m, dtype = \"int32\")\n",
    "    for i in range(len(y_hat)):\n",
    "        if(y_hat[i] >= 0.5):\n",
    "            y_temp[i] = int(1)\n",
    "            \n",
    "    accuracy = 100*(np.sum(y == y_temp)/m)\n",
    "    print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37eb4d3",
   "metadata": {},
   "source": [
    "#### Evaluation on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d925493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/216 [==============================] - 9s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "output1 = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a7551d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.2891112077715\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.nn.sigmoid(output1)\n",
    "y = y_train\n",
    "model_eval(y, y_hat)\n",
    "# del output1\n",
    "# del y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84843b9c",
   "metadata": {},
   "source": [
    "#### Evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d83de945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "output2 = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6e3e2775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.64982373678026\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.nn.sigmoid(output2)\n",
    "y = y_test\n",
    "model_eval(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9acce47",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd7fe29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../my data/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88afa0",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"../my data/model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
